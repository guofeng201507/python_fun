# -*- coding: utf-8 -*-
"""Nomura.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mBBbjdBsotO6_1X-fK6coqYurGSh0bfG
"""

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

columns = ["datetime", "mid"]

"""## **ASSUMPTION: **
Based on the observation, fx_a, fx_b, fx_c contain the price at each minute, not the change of the price at each minute.

Thus, if the consecutive value at "mid" column stay the same as previous, it means the price did not change.

## **Question (a)**
"""

def numChanges(x):
    return sum(x.iloc[:-1] != x.shift(-1).iloc[:-1])

def find_liquid_hr(df):
  df['Dates'] = pd.to_datetime(df['datetime']).dt.date
  df['Time'] = pd.to_datetime(df['datetime']).dt.time
  df['Hour'] = pd.to_datetime(df['datetime']).dt.hour

  df = df.drop(['datetime'], axis=1)
 
  result  = df.groupby('Hour').agg({
    'mid' : numChanges
})
  result.reset_index(inplace=True)

  result.columns = ['Hour', 'no_changes']
  result = result.sort_values(by=['no_changes'], ascending=False)

  return result.head(10)

def find_volatile_hr(df, liq_hr):
  df = df[df['Hour'].isin(liq_hr)]

  df['Dates'] = pd.to_datetime(df['datetime']).dt.date
  df['Time'] = pd.to_datetime(df['datetime']).dt.time
  df['Hour'] = pd.to_datetime(df['datetime']).dt.hour

  df = df.drop(['datetime'], axis=1)

  stat = df.groupby(['Dates', 'Hour']).describe()

  stat = stat.reset_index()
  stat_std = stat[['Dates', 'Hour']].copy()
  stat_std['std'] = stat['mid']['std']

  avg_std = stat_std.groupby(['Hour']).mean()
  avg_std = avg_std.reset_index()
  avg_std.sort_values(['std'], ascending=False, inplace=True)

  return avg_std['Hour'].tolist()

"""fx_a"""

fx_a = pd.read_csv('/content/drive/MyDrive/Nomura/fx_a.csv', names=columns, skiprows=1)
fx_a.head()

fx_a.tail(20)

result_a = find_liquid_hr(fx_a)
liq_hr_a = result_a['Hour'].tolist()
liq_hr_a

"""fx_b"""

fx_b = pd.read_csv('/content/drive/MyDrive/Nomura/fx_b.csv', names=columns, skiprows=1)
fx_b.head()

result_b = find_liquid_hr(fx_b)
liq_hr_b = result_b['Hour'].tolist()
liq_hr_b

"""fx_c"""

fx_c = pd.read_csv('/content/drive/MyDrive/Nomura/fx_c.csv', names=columns, skiprows=1)
fx_c.head()

result_c = find_liquid_hr(fx_c)
liq_hr_c = result_c['Hour'].tolist()
liq_hr_c

"""## **Question (b)**"""

df_a = fx_a.copy()

volat_hours_a = find_volatile_hr(df_a, liq_hr_a)

volat_hours_a

df_b = fx_b.copy()

volat_hours_b = find_volatile_hr(df_b, liq_hr_b)

volat_hours_b

df_c = fx_c.copy()

volat_hours_c = find_volatile_hr(df_c, liq_hr_c)

volat_hours_c

"""## **Question (c)**"""

weights = pd.read_csv('/content/drive/MyDrive/Nomura/weights.csv')
weights.head(10)

weights.tail(10)

weights[['fx_a', 'fx_b','fx_c']].apply(pd.Series.value_counts)

weights['datetime'] = pd.to_datetime(weights['time'])

weights_filtered = weights[(weights['datetime'] > '2019-03-30 23:00:00') & (weights['datetime'] <= '2021-04-02 01:00:00')]
weights_filtered.drop(['time'], axis=1, inplace=True)
weights_filtered

weights_filtered[['fx_a', 'fx_b','fx_c']].apply(pd.Series.value_counts)

def process_fx_for_hr_trade(fx_df):
  fx_datetime = fx_df.copy()
  fx_datetime['Dates'] = pd.to_datetime(fx_datetime['datetime']).dt.date
  fx_datetime['Time'] = pd.to_datetime(fx_datetime['datetime']).dt.time
  fx_datetime['Hour'] = pd.to_datetime(fx_datetime['datetime']).dt.hour

  fx_hr = fx_datetime.groupby(['Dates','Hour']).tail(1)

  fx_hr['datetime'] = fx_hr['Dates'].astype(str) + ' ' + fx_hr['Time'].astype(str).str[:2] + ':00:00'

  fx_hr = fx_hr.drop(['Dates', 'Time', 'Hour'], axis=1)

  return fx_hr

"""# fx_a, fx_b, fx_c return

fx_a return
"""

fx_a_hr_price = process_fx_for_hr_trade(fx_a)
fx_a_hr_price

trades_a = weights_filtered[weights_filtered['fx_a'] != 0 ][['fx_a', 'datetime']]
trades_a['datetime'] = trades_a['datetime'].astype(str)

trades_a = pd.merge(trades_a, fx_a_hr_price, how='inner', on=['datetime'])
trades_a['amount'] = 100* trades_a['fx_a'] * trades_a['mid']

return_a = trades_a['amount'].sum()
return_a

"""fx_a return is 85492.62299999993

fx_b return
"""

fx_b_hr_price = process_fx_for_hr_trade(fx_b)
fx_b_hr_price

trades_b = weights_filtered[weights_filtered['fx_b'] != 0 ][['fx_b', 'datetime']]
trades_b['datetime'] = trades_b['datetime'].astype(str)

trades_b = pd.merge(trades_b, fx_b_hr_price, how='inner', on=['datetime'])
trades_b['amount'] = 100* trades_b['fx_b'] * trades_b['mid']

return_b = trades_b['amount'].sum()
return_b

"""fx_b return is 106533.77100000232

fx_c return
"""

fx_c_hr_price = process_fx_for_hr_trade(fx_c)
fx_c_hr_price

trades_c = weights_filtered[weights_filtered['fx_c'] != 0 ][['fx_c', 'datetime']]
trades_c['datetime'] = trades_c['datetime'].astype(str)

trades_c = pd.merge(trades_c, fx_c_hr_price, how='inner', on=['datetime'])
trades_c['amount'] = 100* trades_c['fx_c'] * trades_c['mid']

return_c = trades_c['amount'].sum()
return_c

"""fx_c return is 26650.141999999963

## **Question (d)**

This can be achieved by adjust method of converting minute data to hourly data. 

In order to check every minutes, will test with timeslot which contains full hour data. 

( 2019-04-02 ~ 2021-02-07)
"""

def process_fx_for_hr_trade_flexible_minute(fx_df, minute):
  fx_datetime = fx_df.copy()
  fx_datetime['Dates'] = pd.to_datetime(fx_datetime['datetime']).dt.date
  fx_datetime['Time'] = pd.to_datetime(fx_datetime['datetime']).dt.time
  fx_datetime['Hour'] = pd.to_datetime(fx_datetime['datetime']).dt.hour
  fx_datetime['minute'] = pd.to_datetime(fx_datetime['datetime']).dt.minute

  fx_datetime = fx_datetime[fx_datetime['minute'] == minute]  

  fx_datetime['datetime'] = fx_datetime['Dates'].astype(str) + ' ' + fx_datetime['Time'].astype(str).str[:2] + ':00:00'

  fx_datetime = fx_datetime.drop(['Dates', 'Time', 'Hour', 'minute'], axis=1)

  return fx_datetime.copy()

minutes = range(0, 60)
result_every_minute = []

for minute in minutes:
  fx_a_hr_price = process_fx_for_hr_trade_flexible_minute(fx_a, minute)

  trades_a = trades_a.iloc[0:0]
  trades_a = weights_filtered[weights_filtered['fx_a'] != 0 ][['fx_a', 'datetime']]
  trades_a['datetime'] = trades_a['datetime'].astype(str)

  trades_a = pd.merge(trades_a, fx_a_hr_price, how='inner', on=['datetime'])
  trades_a['amount'] = 100* trades_a['fx_a'] * trades_a['mid']

  return_a = trades_a['amount'].sum()

  result_every_minute.append(return_a)

result_every_minute

experiment_output = zip(list(minutes), result_every_minute)

df = pd.DataFrame(list(experiment_output))
df.columns=['minute', 'return']
df.head(60)

"""Actually there is **no major difference** on which minute the trade should executed."""